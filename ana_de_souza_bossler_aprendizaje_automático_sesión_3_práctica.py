# -*- coding: utf-8 -*-
"""Ana de Souza Bossler Aprendizaje Automático - Sesión 3 - Práctica

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18rIACucXe0L2PMzcJqqMWLv1SI-wkAIe

<img src='https://drive.google.com/uc?id=1DHE8rHnhKRam8LrZpOkVY6iF3GMK7Jwf' caption="Máster Universitario en Automática y Robótica"></center>

# Aprendizaje Automático
## Práctica 3

Profesor: **Jose Javier Valero Mas**

### Ejercicio

La tarea a realizar consistirá en poner en práctica los conceptos prácticos introducidos en esta sesión.

Para ello el alumno deberá:

* Cargar la base de datos ***MNIST*** (que hemos utilizado ya en las prácticas):
  * La parte de ***Test*** deberá ser el fichero de que ya está etiquetado como tal
  * La parte de ***Train*** deberá ser también el fichero que está definido así en Colab. Sin embargo, haremos una partición de ***Validation*** en este caso que serán las ***10.000 últimas*** muestras de ese conjunto 

* En base a ello crearéis diferentes modelos de red (más o menos capas, con diferentes optimizadores...) que entrenaréis con ***Train*** y validaréis con ***Validation***.
* Una vez hayáis hecho diferentes pruebas de configuraciones, deberéis escoger la que os maximiza la tasa de acierto en ***Validation*** y evaluar su respuesta en el conjunto de ***Test***.

### Entrega

  * Haz una copia de este archivo ("Archivo" > "Guardar una copia en drive").

  * Realiza la práctica descrita en el apartado anterior sobre el nuevo archivo. Documenta los pasos que vas realizando incrustando texto en Colab.

  * Genera un enlace para compartir (acuérdate de dar los permisos apropiados). Copia y pega el enlace en la entrega habilitada en el Moodle de la asignatura.

1. Importamos las librerías y la base de datos mnist, definimos las variables
"""

import numpy
import theano
import tensorflow as tf
import keras

print('TensorFlow version: {}'.format(tf.__version__))
print('tf.keras version: {}'.format(tf.keras.__version__))
print('Keras version: {}'.format(keras.__version__))

import numpy as np
np.random.seed(123) 
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Convolution2D, MaxPooling2D
from keras.utils import np_utils
from sklearn.model_selection import train_test_split

# Commented out IPython magic to ensure Python compatibility.
(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.mnist.load_data()

# Dimensiones de los datos
print("Datos de entrenamiento - Imagenes: {} - Etiquetas: {}".format(X_train.shape,Y_train.shape))
print("Datos de test - Imagenes: {} - Etiquetas: {}".format(X_test.shape,Y_test.shape))
print()

# Visualización de ejemplo
import matplotlib
import matplotlib.pyplot as plt
# %matplotlib inline

example_id = 10

plt.imshow(X_train[example_id],cmap='gray')
plt.show()
print("Ejemplo etiqueta: {}".format(Y_train[example_id]))

"""Transformamos los datos, primero el X"""

X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)
X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)

X_train = X_train.astype('float32')
X_test = X_test.astype('float32')
X_train /= 255
X_test /= 255

print(X_train.shape)

print(Y_train[:30])

X_train = X_train.reshape(-1, 784)
X_test = X_test.reshape(-1, 784)

Y_train = np_utils.to_categorical(Y_train, 10)
Y_test = np_utils.to_categorical(Y_test, 10)
print(Y_train.shape)
print(Y_test.shape)

X_val = X_train[50000:60000]
Y_val = Y_train[50000:60000]

X_testw = X_test[0:50000]
Y_testw = Y_test[0:50000]

print(X_val.shape)
print(Y_val.shape)

model = tf.keras.Sequential()
model.add(tf.keras.layers.Input(shape=(784,)))
model.add(tf.keras.layers.Dense(512, activation='relu'))
model.add(tf.keras.layers.Dense(10, activation='softmax'))              

# Resumen
model.summary()

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

history = model.fit(X_train, Y_train, validation_split=0.16, epochs=15, verbose=2)

# Claves del diccionario
print(history.history.keys())

# Pintamos la precisión en entrenamiento y validación
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.xlabel('epoch')         # Eje X - Época
plt.ylabel('accuracy')      # Eje Y - Precisión
plt.legend(['train', 'validation'])
plt.show()

loss, accuracy = model.evaluate(X_test, Y_test, verbose=0)

print("Precision sobre test: {}".format(accuracy))

model = tf.keras.Sequential()
model.add(tf.keras.layers.Input(shape=(784,)))
model.add(tf.keras.layers.Dense(300, activation='relu'))
model.add(tf.keras.layers.Dense(10, activation='softmax'))              

# Resumen
model.summary()

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

history = model.fit(X_train, Y_train, validation_split=0.16, epochs=15, verbose=2)

# Claves del diccionario
print(history.history.keys())

# Pintamos la precisión en entrenamiento y validación
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.xlabel('epoch')         # Eje X - Época
plt.ylabel('accuracy')      # Eje Y - Precisión
plt.legend(['train', 'validation'])
plt.show()

loss, accuracy = model.evaluate(X_test, Y_test, verbose=0)

print("Precision sobre test: {}".format(accuracy))

model = Sequential()
model.add(Dense(512, activation='sigmoid', input_shape=(784,)))
model.add(Dense(10, activation='softmax'))

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

history = model.fit(X_train, Y_train, validation_split=0.16, epochs=15, verbose=2)

# Claves del diccionario
print(history.history.keys())

# Pintamos la precisión en entrenamiento y validación
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.xlabel('epoch')         # Eje X - Época
plt.ylabel('accuracy')      # Eje Y - Precisión
plt.legend(['train', 'validation'])
plt.show()

loss, accuracy = model.evaluate(X_test, Y_test, verbose=0)

print("Precision sobre test: {}".format(accuracy))

model = Sequential()
model.add(Dense(512, activation='tanh', input_shape=(784,)))
model.add(Dense(10, activation='softmax'))
model.summary()

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

history = model.fit(X_train, Y_train, validation_split=0.16, epochs=15, verbose=2)

# Claves del diccionario
print(history.history.keys())

# Pintamos la precisión en entrenamiento y validación
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.xlabel('epoch')         # Eje X - Época
plt.ylabel('accuracy')      # Eje Y - Precisión
plt.legend(['train', 'validation'])
plt.show()

loss, accuracy = model.evaluate(X_test, Y_test, verbose=0)

print("Precision sobre test: {}".format(accuracy))

"""Cambiando las funciones de activación no se ha podido mejorar la precisión y relu se ha portado mejor. Continuaremos con cambios en el número de neuronas  de la hidden layer con relu y softmax. Con Mnist hay 784 neuronas de entrada representando cada pixel de la imagen, 512 neuronas (que se pueden aumentar o disminuir) como hidden layer y 10 neuronas de salida que representan cada dígito de 0 a 9. Vemos que alterando las 512 capas ocultas a 800 se ha aumentado ligeramente la precisión. Analizando las activaciones diferentes vemos que na primeira relu con 512 capas ocultas la validación se mantiene a partir de la 2 época y el entreinamiento continúa a subir, succediendo lo mismo con la segunda que utiliza 300 capas. Con sigmóide la validación se estabiliza en la 3 época y con Tahn en la 2. Con 800 capas ocultas esto succ




"""

model = tf.keras.Sequential()
model.add(tf.keras.layers.Input(shape=(784,)))
model.add(tf.keras.layers.Dense(800, activation='relu'))
model.add(tf.keras.layers.Dense(10, activation='softmax'))              

# Resumen
model.summary()

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

history = model.fit(X_train, Y_train, validation_split=0.16, epochs=15, verbose=2)

# Claves del diccionario
print(history.history.keys())

# Pintamos la precisión en entrenamiento y validación
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.xlabel('epoch')         # Eje X - Época
plt.ylabel('accuracy')      # Eje Y - Precisión
plt.legend(['train', 'validation'])
plt.show()

loss, accuracy = model.evaluate(X_test, Y_test, verbose=0)

print("Precision sobre test: {}".format(accuracy))

import tensorflow_datasets as tfds

train, test = tfds.load("mnist", as_supervised=True)

X_train_50000_60000_ds = tfds.load('mnist', split='train[50000:60000]')
Y_train_50000_60000_ds = tfds.load('mnist', split='train[50000:60000]')

X_test_0_50000_ds = tfds.load('mnist', split='train[0:50000]')
Y_test_0_50000_ds = tfds.load('mnist', split='train[0:50000]')

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])