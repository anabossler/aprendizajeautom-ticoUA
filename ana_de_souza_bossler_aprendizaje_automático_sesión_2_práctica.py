# -*- coding: utf-8 -*-
"""Ana de Souza Bossler Aprendizaje Automático - Sesión 2 - Práctica

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jH5Gnnktpwk9vYOEum4fDTRKVF4IdLDj

<img src='https://drive.google.com/uc?id=1DHE8rHnhKRam8LrZpOkVY6iF3GMK7Jwf' caption="Máster Universitario en Automática y Robótica"></center>

# Aprendizaje Automático
## Práctica 2

Profesor: **José Javier Valero Mas**

### Ejercicio

La tarea a realizar consistirá en poner en práctica los conceptos prácticos introducidos en esta sesión.

Para ello el alumno deberá:
* Escoger un conjunto de datos desbalanceados para su clasificación
* Evaluar los cuatro clasificadores introducidos en la sesión teórica: $k$NN, Decision Tree, SVM y Random Forest
* Realizar una validación cruzada de k=10 folds
* Proporcionar el valor de la métrica F$_{1}$ para la clase **minoritaria** del conjunto de datos para los diferentes folds
* Promediar los 10 folds de cada clasificador y así concluir cuál se comporta mejor ante el escenario planteado


Para la realización de la misma se deberá utilizar alguno de estos dos conjuntos de datos:
* https://www.vision.uji.es/~sanchez/Databases/phoneme/dataset
* https://www.vision.uji.es/~sanchez/Databases/spam/dataset


### Entrega

  * Haz una copia de este archivo ("Archivo" > "Guardar una copia en drive").

  * Realiza la práctica descrita en el apartado anterior sobre el nuevo archivo. Documenta los pasos que vas realizando incrustando texto en Colab.

  * Genera un enlace para compartir (acuérdate de dar los permisos apropiados). Copia y pega el enlace en la entrega habilitada en el Moodle de la asignatura.

1. Elijo el dataset phoneme/dataset y analizo los datos brevemente. Vemos que los datos están desbalanceados, por ej. la columna 5 tiene 29,3% de los datos como 1 (son binarios, 1 o 0).
"""

import pandas as pd
from sklearn.model_selection import train_test_split

data = pd.read_csv('/content/phoneme - tesisua.csv', header=None, delimiter=',')

X = data.loc[:,0:4]
Y = data.loc[:,5]

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25)

print(data)

data.head()

print(f'The number of rows are {data.shape[0]} \nand the number of columns are {data.shape[1]}')

print(data.dtypes)

data.describe()

def missing(df):
    total=df.isnull().sum().sort_values(ascending=False)
    percent=(df.isnull().sum()*100/df.isnull().count()).sort_values(ascending=False)

missing(data)

data.isnull().sum()

corrMatrix = data.corr()

print (corrMatrix)

"""2.Aplicación de los 4 clasificadores."""

#primero clasificador KNN 
from sklearn import neighbors

###se utiliza los parámetros default: distancia euclídea y k=5
model = neighbors.KNeighborsClassifier().fit(X_train, Y_train)

#predicción sobre la partición de test
Y_predict = model.predict(X_test)

from sklearn.metrics import accuracy_score
acc_sklearn = accuracy_score(Y_test, Y_predict)

print("Acc (sklearn): {}".format(acc_sklearn))

"""En este caso tenemos un ACC de 0.792 por lo que habría acertado un 79,2% de las predicciones realizadas.

Con un árbol de decisión:
"""

from sklearn import tree

#árbol de decisión importado con parámetros default
model = tree.DecisionTreeClassifier().fit(X_train,Y_train)

Y_predict = model.predict(X_test)

print("Acc: {}".format(accuracy_score(Y_test, Y_predict)))

"""Con una SVM:"""

from sklearn.model_selection import train_test_split
import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn import svm

model = svm.SVC().fit(X_train,Y_train)

Y_predict = model.predict(X_test)
print("Acc: {}".format(accuracy_score(Y_test, Y_predict)))

"""Tenemos un ACC de 0.748

Con una random forest.
"""

from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier().fit(X_train,Y_train)
Y_predict = model.predict(X_test)
print("Acc: {}".format(accuracy_score(Y_test, Y_predict)))

"""Tenemos un ACC del 0.847.

Desbalancemos todavía más los datos
"""

import pandas as pd
from sklearn.model_selection import train_test_split

data = pd.read_csv('phoneme - tesisua.csv', header=None, delimiter=',')

X = data.loc[:,0:4]
Y = data.loc[:,5]

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25)

histogr = {i:list(Y).count(i) for i in set(Y)}
print("La distribución inicial de clases es: {}".format(histogr))

data[5].hist()

data_binary = pd.concat([data[data[0]==0][:100], data[data[0]!=0]])

X_binary = data_binary.loc[:,1:]
Y_binary = data_binary.loc[:,0]
Y_binary.iloc[100:]=1
Y_binary = Y_binary.astype('int')
histogr = {i:list(Y_binary).count(i) for i in set(Y_binary)}
print("La distribución binaria y desbalanceada es: {}".format(histogr))

Y_binary.hist()

"""### Probamos con este nuevo dataset

"""

X_binary_train, X_binary_test, Y_binary_train, Y_binary_test = train_test_split(X_binary, Y_binary, test_size = 0.25)

model_binary = tree.DecisionTreeClassifier().fit(X_binary_train,Y_binary_train)

model_binary = neighbors.KNeighborsClassifier().fit(X_binary_train, Y_binary_train)

Y_binary_predict = model_binary.predict(X_test)

from sklearn.metrics import precision_score,recall_score,f1_score

print("Acc:\t{:.4f}".format(accuracy_score(Y_binary_test, Y_binary_predict)))
precision_score(Y_binary_test, Y_binary_predict, average='weighted')
precision_score(Y_binary_test, Y_binary_predict, average='micro')
print("-"*20)
print(precision_score)
print("Acc (all 1s):\t{:.4f}".format(accuracy_score(Y_binary_test, [1 for u in Y_binary_predict])))

"""Tenemos un accuracy del 98.22%, que pasa? Que coincide razonablemente con el número de 0s que tenemos, por lo que el modelo no está aprendiendo. """

Y_binary

5304./5404.

print(model_binary.predict(X_test))
print(len(X_test))
print(sum(model_binary.predict(X_test)))

#Importamos el método para la validación cruzada:
from sklearn.model_selection import cross_val_score

#Creamos un clasificador (árbol de decisión con parámetros por defecto):
model_CV = tree.DecisionTreeClassifier()

#Realizamos la validación cruzada con k=10 particiones:
scores = cross_val_score(model_CV, X_binary, Y_binary, cv=10)

#Mostramos los resultados por cada partición:
print(scores)

#Incluimos el método make_scorer, cambias la métrica porque se suele usar sklearn accuracy pero maker score balancea las clases:
from sklearn.metrics import make_scorer

#Realizamos la misma validación cruzada con k=10 particiones pero usando la métrica F1 sobre la clase 0:
scores = cross_val_score(model_CV, X_binary, Y_binary, cv=10, scoring=make_scorer(f1_score, average='weighted'))

#Mostramos los resultados por cada partición:
print(scores)

data = pd.read_csv('phoneme - tesisua.csv', header=None, delimiter=',')

X = data.loc[:,0:4]
Y = data.loc[:,5]

#Importamos el método para la validación cruzada:
from sklearn.model_selection import cross_val_score

#Creamos un clasificador (árbol de decisión con parámetros por default):
model_CV = tree.DecisionTreeClassifier()

#Realizamos la validación cruzada con k=10 particiones:
scores = cross_val_score(model_CV, X, Y, cv=10)

#Mostramos los resultados por cada partición:
print(scores)
mean = sum(scores)/len(scores)
print('Valor medio:', mean)

#Incluimos el método make_scorer, cambias la métrica porque suele usar sklearn accuracy pero maker score balancea las clases:
from sklearn.metrics import make_scorer

#Realizamos la misma validación cruzada con k=5 particiones pero usando la métrica F1 sobre la clase 0:
scores = cross_val_score(model_CV, X, Y, cv=10, scoring=make_scorer(f1_score, average='weighted'))

#Mostramos los resultados por cada partición:
print(scores)
mean = sum(scores)/len(scores)
print('Valor medio:', mean)

#Importamos el método para la validación cruzada:
from sklearn.model_selection import cross_val_score

#Creamos un clasificador (árbol de decisión con parámetros por default):
from sklearn.ensemble import RandomForestClassifier
model_CV = RandomForestClassifier()

#Realizamos la validación cruzada con k=10 particiones:
scores = cross_val_score(model_CV, X, Y, cv=10)

#Mostramos los resultados por cada partición:
print(scores)
mean = sum(scores)/len(scores)
print('Valor medio:', mean)

#Incluimos el método make_scorer, cambias la métrica porque suele usar sklearn accuracy pero maker score balancea las clases:
from sklearn.metrics import make_scorer

#Realizamos la misma validación cruzada con k=5 particiones pero usando la métrica F1 sobre la clase 0:
scores = cross_val_score(model_CV, X, Y, cv=10, scoring=make_scorer(f1_score, average='weighted'))

#Mostramos los resultados por cada partición:
print(scores)
mean = sum(scores)/len(scores)
print('Valor medio:', mean)

"""F1 Precisión y recall """

data = pd.read_csv('phoneme - tesisua.csv', header=None, delimiter=',')

X = data.loc[:,0:4]
Y = data.loc[:,5]

from sklearn.model_selection import KFold
from sklearn.metrics import f1_score
from sklearn.metrics import multilabel_confusion_matrix
import matplotlib.pyplot as plt

kf = KFold(n_splits=10)
kf.get_n_splits(X)

print(kf)
k=0
for train_index, test_index in kf.split(X):
    #print("TRAIN:", train_index, "TEST:", test_index)
    X_train, X_test = X.loc[train_index], X.loc[test_index]
    y_train, y_test = Y.loc[train_index], Y.loc[test_index]
    model = RandomForestClassifier().fit(X_train, y_train)
    Y_predict = model.predict(X_test)
    print('fold: ',k)
    print("F1 score: {}".format(f1_score(y_test, Y_predict,pos_label=1, average='binary')))
    print("Acc: {}".format(accuracy_score(y_test, Y_predict)))
    fig, (ax1, ax2) = plt.subplots(1, 2)
    
    ax1.imshow(multilabel_confusion_matrix(y_test, Y_predict)[0], cmap='binary')
    ax1.set_title('label: 0')
    for i in range(2):
        for j in range(2):
            text = ax1.text(j, i, multilabel_confusion_matrix(y_test, Y_predict)[0][i, j],
                       ha="center", va="center", color="g")
    ax2.imshow(multilabel_confusion_matrix(y_test, Y_predict)[1], cmap='binary')
    ax2.set_title('label: 1')
    for i in range(2):
        for j in range(2):
            text = ax2.text(j, i, multilabel_confusion_matrix(y_test, Y_predict)[1][i, j],
                       ha="center", va="center", color="g")
    plt.show()
    
    TN = multilabel_confusion_matrix(y_test, Y_predict)[1][0,0]
    FP = multilabel_confusion_matrix(y_test, Y_predict)[1][0,1]
    FN = multilabel_confusion_matrix(y_test, Y_predict)[1][1,0]
    TP = multilabel_confusion_matrix(y_test, Y_predict)[1][1,1]
    
    recall = TP/(TP+FN)
    precision = TP/(TP+FP)
    
    f1_calculado = 2 * (precision * recall) / (precision + recall)
    print('F1 calculado', f1_calculado)
    
    k += 1

"""Cross-validation



"""

data = pd.read_csv('phoneme - tesisua.csv', header=None, delimiter=',')

X = data.loc[:,0:4]
Y = data.loc[:,5]

kf = KFold(n_splits=10, shuffle = True)
kf.get_n_splits(X)

print(kf)
k= 1
F1 = 0
acc = 0
for train_index, test_index in kf.split(X):
    #print("TRAIN:", train_index, "TEST:", test_index)
    X_train, X_test = X.loc[train_index], X.loc[test_index]
    y_train, y_test = Y.loc[train_index], Y.loc[test_index]
    model = RandomForestClassifier().fit(X_train, y_train)
    Y_predict = model.predict(X_test)
    print('fold: ',k)
    print("F1 score: {}".format(f1_score(y_test, Y_predict,pos_label=1, average='binary')))
    print("Acc: {}".format(accuracy_score(y_test, Y_predict)))
    F1 += f1_score(y_test, Y_predict,pos_label=1, average='binary')
    acc += accuracy_score(y_test, Y_predict)
    k += 1

print()
print('mean F1', F1/10)
print('mean Acc', acc/10)

data = pd.read_csv('phoneme - tesisua.csv', header=None, delimiter=',')

X = data.loc[:,0:4]
Y = data.loc[:,5]

kf = KFold(n_splits=10, shuffle = True)
kf.get_n_splits(X)

print(kf)
k= 1
F1 = 0
acc = 0
for train_index, test_index in kf.split(X):
    #print("TRAIN:", train_index, "TEST:", test_index)
    X_train, X_test = X.loc[train_index], X.loc[test_index]
    y_train, y_test = Y.loc[train_index], Y.loc[test_index]
    model = tree.DecisionTreeClassifier().fit(X_train, y_train)
    Y_predict = model.predict(X_test)
    print('fold: ',k)
    print("F1 score: {}".format(f1_score(y_test, Y_predict,pos_label=1, average='binary')))
    print("Acc: {}".format(accuracy_score(y_test, Y_predict)))
    F1 += f1_score(y_test, Y_predict,pos_label=1, average='binary')
    acc += accuracy_score(y_test, Y_predict)

    k += 1

print('mean F1', F1/10)
print('mean Acc', acc/10)

data = pd.read_csv('phoneme - tesisua.csv', header=None, delimiter=',')

X = data.loc[:,0:4]
Y = data.loc[:,5]

kf = KFold(n_splits=10, shuffle = True)
kf.get_n_splits(X)

print(kf)
k= 1
F1 = 0
acc = 0
for train_index, test_index in kf.split(X):
    #print("TRAIN:", train_index, "TEST:", test_index)
    X_train, X_test = X.loc[train_index], X.loc[test_index]
    y_train, y_test = Y.loc[train_index], Y.loc[test_index]
    model = neighbors.KNeighborsClassifier().fit(X_train, y_train)
    Y_predict = model.predict(X_test)
    print('fold: ',k)
    print("F1 score: {}".format(f1_score(y_test, Y_predict,pos_label=1, average='binary')))
    print("Acc: {}".format(accuracy_score(y_test, Y_predict)))
    F1 += f1_score(y_test, Y_predict,pos_label=1, average='binary')
    acc += accuracy_score(y_test, Y_predict)

    k += 1

print('mean F1', F1/k)
print('mean Acc', acc/k)

data = pd.read_csv('phoneme - tesisua.csv', header=None, delimiter=',')

X = data.loc[:,0:4]
Y = data.loc[:,5]

kf = KFold(n_splits=10, shuffle = True)
kf.get_n_splits(X)

print(kf)
k= 1
F1 = 0
acc = 0
for train_index, test_index in kf.split(X):
    #print("TRAIN:", train_index, "TEST:", test_index)
    X_train, X_test = X.loc[train_index], X.loc[test_index]
    y_train, y_test = Y.loc[train_index], Y.loc[test_index]
    model = svm.SVC().fit(X_train, y_train)
    Y_predict = model.predict(X_test)
    print('fold: ',k)
    print("F1 score: {}".format(f1_score(y_test, Y_predict, pos_label=1, average='binary')))
    print("Acc: {}".format(accuracy_score(y_test, Y_predict)))
    F1 += f1_score(y_test, Y_predict, pos_label=1, average='binary')
    acc += accuracy_score(y_test, Y_predict)

    k += 1

print('mean F1', F1/10)
print('mean Acc', acc/10)

"""Conclusiones:

Promedio F1 del grupo minoritario (pos label = 1, average = binary, F1/10).

Random Forest = 72.4%

Decision Trees = 62.9%

KNN = 59,9%

SVM= 35.82%


El con mejor comportamiento es el Random Forest, lo que parece razonable porque es un conjunto de árboles de decisión entonces sería mejor que una decision tree. Ahora, dado que F1 = (2 x recall x precision) / (recall + precision) buscamos clasificadores que sean igualmente "buenos" en recall y precision en vez de priorizar uno a otro. Por lo que tenemos:

Random Forest

ACC=
Recall=

Decision Trees 

ACC=
Recall=

KNN

ACC=
Recall=

SVM

ACC=
Recall=




"""